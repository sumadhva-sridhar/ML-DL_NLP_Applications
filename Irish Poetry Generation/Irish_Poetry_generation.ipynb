{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Irish Poetry generation",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsOumSHEi50f",
        "colab_type": "text"
      },
      "source": [
        "###Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xgT0rRDiXKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD5Od1vDjILb",
        "colab_type": "text"
      },
      "source": [
        "###Download and store the required dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A4kGFGojN-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/irish-lyrics-eof.txt \\\n",
        "    -O /tmp/irish-lyrics-eof.txt\n",
        "\n",
        "data = open('/tmp/irish-lyrics-eof.txt').read()\n",
        "corpus = data.lower().split(\"\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwJrKNtxjX1N",
        "colab_type": "text"
      },
      "source": [
        "###Tokenize the dataset and split it into inputs and outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu6JcaeKjXZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Create the tokenizer and fit it on the corpus\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Add all sequences of words to the dataset\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Ensure that all training examples are of the same length\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen = max_sequence_len, padding = 'pre'))\n",
        "\n",
        "# Define the inputs and their labels\n",
        "xs, labels = input_sequences[:,:-1], input_sequences[:,-1]\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes = total_words)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MtIyo9CjoRp",
        "colab_type": "text"
      },
      "source": [
        "###Define and train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJCCfjlblGAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "ip_model = tf.keras.models.Sequential()\n",
        "ip_model.add(tf.keras.layers.Embedding(total_words, 100, input_length = max_sequence_len-1))\n",
        "ip_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(200)))\n",
        "ip_model.add(tf.keras.layers.Dense(total_words, activation = 'softmax'))\n",
        "\n",
        "ip_model.compile(loss='categorical_crossentropy',\n",
        "                 optimizer = tf.keras.optimizers.Adam(lr = 0.01),\n",
        "                 metrics = ['accuracy'])\n",
        "\n",
        "history = ip_model.fit(xs, ys,\n",
        "                       epochs = 100,\n",
        "                       verbose = 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdhCSX_hwpG7",
        "colab_type": "text"
      },
      "source": [
        "###Plot the accuracy of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ4OLRWNl-an",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\", color = \"white\")\n",
        "  plt.ylabel(string, color = \"white\")\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjCZdgvbmENH",
        "colab_type": "text"
      },
      "source": [
        "###Test the model using some initial text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFPNzcZBmMcp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "seed_text = \"I have a bad feeling about this\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen = max_sequence_len-1, padding = 'pre')\n",
        "\tpredicted = ip_model.predict_classes(token_list, verbose = 0)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}